[
  {
    "question": "A company uses Amazon EC2 Reserved Instances to run its data processing workload. The nightly job typically takes 7 hours to run and must finish within a 10-hour time window. The company anticipates temporary increases in demand at the end of each month that will cause the job to run over the time limit with the capacity of the current resources. Once started, the processing job cannot be interrupted before completion. The company wants to implement a solution that would provide increased resource capacity as cost-effectively as possible.\nWhat should a solutions architect do to accomplish this?",
    "options": {
      "A": "Deploy On-Demand Instances during periods of high demand.",
      "B": "Create a second EC2 reservation for additional instances.",
      "C": "Deploy Spot Instances during periods of high demand.",
      "D": "Increase the EC2 instance size in the EC2 reservation to support the increased workload."
    },
    "correctAnswer": "A",
    "explanation": "**On-Demand Instances** are suitable for workloads that are short-term, spiky, or unpredictable and cannot be interrupted. Spot Instances are cheaper but can be interrupted, which is not suitable as the job cannot be interrupted. A new reservation would be costly for temporary demand and isn't flexible for infrequent peaks. Increasing the size of the existing reservation might be overkill for temporary increases and less cost-effective than using On-Demand capacity only when needed."
  },
  {
    "question": "A company is migrating its on-premises three-tier web application to AWS. The application requires a relational database. The company wants a managed database solution that minimizes administrative overhead, supports automatic patching, backups, and offers high availability with a Multi-AZ deployment option.\nWhich AWS service should the solutions architect recommend for the database tier?",
    "options": {
      "A": "Amazon DynamoDB",
      "B": "Amazon EC2 instances with a self-managed database",
      "C": "Amazon RDS",
      "D": "Amazon Redshift"
    },
    "correctAnswer": "C",
    "explanation": "**Amazon RDS (Relational Database Service)** is a managed service that simplifies setting up, operating, and scaling a relational database in the cloud. It supports Multi-AZ deployments for high availability, automated patching, and backups, meeting all the company's requirements for a managed relational database. DynamoDB is a NoSQL database. EC2 with a self-managed database increases administrative overhead. Amazon Redshift is a data warehousing service, not primarily designed for transactional application backends."
  },
  {
    "question": "A development team needs to store and share Docker container images securely within their AWS environment. They require a fully managed service that integrates well with Amazon ECS and EKS. The service should also support versioning of images.\nWhich AWS service is most appropriate for this requirement?",
    "options": {
      "A": "Amazon S3",
      "B": "Amazon EFS",
      "C": "Amazon ECR (Elastic Container Registry)",
      "D": "AWS CodeArtifact"
    },
    "correctAnswer": "C",
    "explanation": "**Amazon ECR (Elastic Container Registry)** is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. It integrates seamlessly with Amazon ECS (Elastic Container Service) and Amazon EKS (Elastic Kubernetes Service) and natively supports image versioning. While S3 can store files, it's not a specialized container registry. EFS provides file storage. AWS CodeArtifact is a repository for software packages, not specifically container images."
  },
  {
    "question": "A company is launching a new public-facing website and expects significant, unpredictable traffic spikes. They want to ensure the website remains available and responsive, and they want to protect it from common web exploits like SQL injection and cross-site scripting (XSS).\nWhich combination of AWS services should be used to meet these requirements?",
    "options": {
      "A": "Amazon EC2 Auto Scaling, Application Load Balancer, and AWS Shield Standard",
      "B": "Amazon EC2 Auto Scaling, Application Load Balancer, and AWS WAF",
      "C": "Amazon CloudFront, Amazon S3 (for static content), and AWS Shield Advanced",
      "D": "Amazon Route 53 Latency-based routing and AWS Firewall Manager"
    },
    "correctAnswer": "B",
    "explanation": "**Amazon EC2 Auto Scaling** allows the application to scale out or in based on demand, ensuring availability and responsiveness during traffic spikes. An Application Load Balancer (ALB) distributes incoming traffic across multiple EC2 instances. AWS WAF (Web Application Firewall) helps protect web applications from common web exploits such as SQL injection and XSS. AWS Shield Standard provides DDoS protection for all AWS customers, but WAF is specifically for application-layer attacks."
  },
  {
    "question": "A company wants to establish a dedicated, private network connection between its on-premises data center and its AWS VPC. The connection needs to provide consistent low-latency performance and high bandwidth for transferring large datasets.\nWhich AWS service should the company use to establish this connection?",
    "options": {
      "A": "AWS VPN (Site-to-Site VPN)",
      "B": "AWS Direct Connect",
      "C": "VPC Peering",
      "D": "AWS Transit Gateway"
    },
    "correctAnswer": "B",
    "explanation": "**AWS Direct Connect** is a cloud service solution that makes it easy to establish a dedicated network connection from your premises to AWS. Using AWS Direct Connect, you can establish private connectivity between AWS and your datacenter, office, or colocation environment, which can reduce your network costs, increase bandwidth throughput, and provide a more consistent network experience than Internet-based connections. AWS VPN creates a secure connection over the public internet. VPC Peering connects two VPCs. AWS Transit Gateway is a network hub to connect VPCs and on-premises networks, but Direct Connect provides the dedicated physical circuit."
  },
  {
    "question": "A company needs to store frequently accessed, critical data in Amazon S3. They require the highest level of durability and availability. Data must be resilient to the failure of an entire AWS Availability Zone. Cost is a secondary concern compared to data resilience.\nWhich S3 storage class should be used?",
    "options": {
      "A": "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "B": "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "C": "S3 Standard",
      "D": "S3 Glacier Deep Archive"
    },
    "correctAnswer": "C",
    "explanation": "**S3 Standard** offers high durability (99.999999999%) and availability (99.99%) by redundantly storing data across multiple Availability Zones (typically 3 or more). This makes it resilient to the failure of a single AZ. S3 Standard-IA is for less frequently accessed data but still offers multi-AZ resilience. S3 One Zone-IA stores data in a single AZ and is not resilient to an AZ failure. S3 Glacier Deep Archive is for long-term archival with retrieval times of hours and is not suitable for frequently accessed data."
  },
  {
    "question": "A solutions architect is designing a serverless application that uses AWS Lambda functions to process images uploaded to an Amazon S3 bucket. The Lambda functions need permission to read objects from the S3 bucket and write logs to Amazon CloudWatch Logs.\nWhat is the MOST secure way to grant these permissions to the Lambda functions?",
    "options": {
      "A": "Create an IAM user with the necessary permissions and embed its access keys in the Lambda function code.",
      "B": "Create an IAM role with the necessary permissions and assign it to the Lambda functions as their execution role.",
      "C": "Configure the S3 bucket policy to allow access from the Lambda function's ARN and a similar policy for CloudWatch Logs.",
      "D": "Store IAM user credentials in AWS Secrets Manager and retrieve them within the Lambda function code."
    },
    "correctAnswer": "B",
    "explanation": "The most secure way to grant permissions to AWS services like Lambda is by **using IAM roles**. An IAM execution role is assumed by the Lambda function at runtime, granting it temporary credentials with the defined permissions. Embedding access keys (A) or retrieving them from Secrets Manager for this purpose (D) is less secure and more complex than using execution roles. While resource-based policies like S3 bucket policies (C) can grant access, an IAM execution role is the standard and recommended best practice for Lambda permissions as it centralizes the function's entitlements."
  },
  {
    "question": "An application running on Amazon EC2 instances processes sensitive user data. The company has a strict compliance requirement that all data stored at rest must be encrypted. The application writes data to Amazon EBS volumes attached to the EC2 instances.\nHow can a solutions architect ensure the data on the EBS volumes is encrypted at rest?",
    "options": {
      "A": "Encrypt the data within the application before writing it to the EBS volumes.",
      "B": "Enable EBS encryption by default for the AWS Region.",
      "C": "Use AWS Shield to encrypt the EBS volumes.",
      "D": "Store the data in an encrypted S3 bucket and mount it to the EC2 instances using AWS Storage Gateway."
    },
    "correctAnswer": "B",
    "explanation": "**Enabling EBS encryption by default for the AWS Region** ensures that all new EBS volumes created in that region are automatically encrypted at rest using AWS KMS. This is a simple and effective way to meet the compliance requirement. While application-level encryption (A) is possible, it adds complexity. AWS Shield (C) is for DDoS protection, not EBS encryption. Using S3 via Storage Gateway (D) changes the storage architecture and is not a direct solution for encrypting existing EBS volumes at rest."
  },
  {
    "question": "A company wants to monitor the performance of its web application, which is deployed across several Amazon EC2 instances behind an Application Load Balancer (ALB). They need to collect metrics such as CPU utilization, network traffic, and request latency for both the EC2 instances and the ALB. They also want to create alarms based on these metrics.\nWhich AWS service should they primarily use for this purpose?",
    "options": {
      "A": "AWS CloudTrail",
      "B": "Amazon CloudWatch",
      "C": "AWS Config",
      "D": "Amazon Inspector"
    },
    "correctAnswer": "B",
    "explanation": "**Amazon CloudWatch** is a monitoring and observability service that collects metrics, logs, and traces from AWS resources, applications, and on-premises servers. It can collect CPU utilization, network traffic from EC2 instances, and request latency from ALBs. CloudWatch also allows users to create alarms based on these metrics. AWS CloudTrail (A) is for logging API activity. AWS Config (C) is for assessing, auditing, and evaluating configurations. Amazon Inspector (D) is a vulnerability management service."
  },
  {
    "question": "A company is building a microservices architecture. They need a way to decouple their microservices so that a failure in one service does not impact others. Messages between services need to be stored durably until they are processed. The order of messages within a specific group of related messages must be maintained.\nWhich AWS service is most suitable for this messaging requirement?",
    "options": {
      "A": "Amazon Simple Notification Service (SNS)",
      "B": "Amazon Kinesis Data Streams",
      "C": "Amazon Simple Queue Service (SQS) FIFO queues",
      "D": "Amazon MQ"
    },
    "correctAnswer": "C",
    "explanation": "**Amazon SQS FIFO (First-In, First-Out)** queues are designed for applications where the order of operations and events is critical, or where duplicates cannot be tolerated. They provide durable message storage and ensure that messages are processed exactly once, in the order they are sent (within a message group). Standard SQS queues don't guarantee order. SNS (A) is a pub/sub messaging service, not primarily for ordered, durable queues. Kinesis Data Streams (B) is for real-time data streaming. Amazon MQ (D) is a managed message broker service for ActiveMQ or RabbitMQ, which could work but SQS FIFO is a more direct AWS-native fit for this specific ordered queuing need."
  }
]
